## Prediction of Exercise Manner from Health Device Data

# Executive Summary

I tested two types of models to try to predict the classe variable: a classification tree model and a linear discriminant model. I used cross validation on the training data set, splitting the training data set into a training set and a test set. Both models were trained on the training portion of the partitioned data, and tested on the test portion of the partitioned data. Based on the testing results, the expected out of sample error rate of the classification tree model is 51% and the expected out of sample error rate of the linear discriminant model is 30%.

Based on the expected out of sample error rates, the linear discriminant model is a far better predictor of the classe variable, and should be used to predict the test set results.

# Setup

Set working directory

```{r,echo=TRUE}
setwd("~/Training/Coursera/Machine Learning")
```

Load the training and testing data

```{r,echo=TRUE}
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
```

Load R packages

```{r,echo=TRUE}
library(ggplot2)
library(plyr)
library(stats)
library(caret)
library(rattle)
library(rpart)
library(MASS)
```

# Refine the training data

Eliminate columns with greater than 50% N/A values

```{r,echo=TRUE}
training2 <- training[colSums(!is.na(training))>nrow(training)*0.5]
```

Eliminate columns which have close to 0 variability

```{r,echo=TRUE}
nsv <- nearZeroVar(training2,saveMetrics=TRUE)
training3 <- training2[-c(6,12:20,43:48,52:60,74:82)]
```

Eliminate meaningless variables (row number, timestamp, user name, num_window)

```{r,echo=TRUE}
training4 <- training3[-c(1:6)]
```

# Partition the refined / modified training data

```{r,echo=TRUE}
inTrain <- createDataPartition(y = training4$classe, p=0.75, list = FALSE)
training_partition <- training4[inTrain,]
testing_partition <- training4[-inTrain,]
```

# Classification tree model (Model 1)

Build a classification tree model on the training portion of the partitioned training data set

```{r,echo=TRUE}
modFit <- train(classe~.,method="rpart",data=training_partition)
print(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
```

Use the model to predict on the testing portion of the partitioned training data set

```{r,echo=TRUE}
pred <- predict(modFit,testing_partition)
```

Estimate the out of sample error by comparing the prediction results to the actual values of the classe variable

```{r,echo=TRUE}
xtab <- table(pred,testing_partition$classe)
cm <- confusionMatrix(xtab)
accuracy_mod1 <- cm$overall['Accuracy']
errrate_mod1 <- 1 - accuracy_mod1
```
The expected out of sample error rate of the classification tree model is equal to or greater than `r errrate_mod1` 

# Linear Discriminant model (Model 2)

Build a Linear Discriminant model on the training portion of the partitioned training data set

```{r,echo=TRUE}
modFit2 <- train(classe~.,method="lda",data=training_partition)
```

Use the model to predict on the testing portion of the partitioned training data set

```{r,echo=TRUE}
pred2 <- predict(modFit2,testing_partition)
```

Estimate the out of sample error by comparing the prediction results to the actual values of the classe variable

```{r,echo=TRUE}
xtab2 <- table(pred2,testing_partition$classe)
cm2 <- confusionMatrix(xtab2)
accuracy_mod2 <- cm2$overall['Accuracy']
errrate_mod2 <- 1 - accuracy_mod2
```
The expected out of sample error rate of the linear disciminant model is equal to or greater than `r errrate_mod2` 


